# Gradient-Boosting Algorithm ğŸ“Š
ğŸ‘¨â€ğŸ’» This repository contains code for evaluating various machine learning models for binary classification.

## Features Selection ğŸ§
ğŸ” Features used for the models are selected through the Feature Importance method using Random Forest.

## Data Import ğŸ“ˆ
The dataset is loaded from "FMat.pkl", and features are extracted for training and testing.

## Data Preprocessing ğŸ”„
Categorical data is encoded using LabelEncoder, and features are normalized.

## Data Split ğŸ§©
The dataset is split into training and testing sets (80% training, 20% testing) with a random seed of 42.

## Models ğŸ¤–
The following models are evaluated:

K-Nearest Neighbors (KNN)
Logistic Regression
Naive Bayes
Decision Tree
Random Forest
LightGBM
XGBoost

## Model Evaluation ğŸ“ˆ
Model performance is assessed using:

- F1-score
- Area Under the Curve (AUC)

## Results ğŸ“Š
Results for each model are displayed, including F1-score and AUC. ğŸš€

Use this code to evaluate the performance of various machine learning models for binary classification tasks. Explore and modify the code for your datasets and model evaluations. ğŸ“š

For more details, refer to the code comments and documentation. Feel free to adapt and improve it for your specific needs. ğŸ˜Š
